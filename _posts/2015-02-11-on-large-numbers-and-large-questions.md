---
layout: post
published: false
title: On Large Numbers and Large Questions
category: commentary
author: Corey Walsh
tags: 
  - Digital_Humanities
---

We have entered an era of information. With this information comes not just power in the ability to learn new insights about ourselves and the world we live in, but the responsibility to do so. This reality raises two important questions:

1. What **can** we do
2. What **should** we do

As _Scale: The Law of Large Numbers_ points out, we as a society are generating more data than we can comprehend, or even store. From a technologist's point of view, "Big Data" brings with it it's own set of challenges and set backs. The amount of computation required to answer questions we are able to pose is a real life bottleneck. Luckily, computers improve, and our knowledge of how to apply things such as parallel algorithms improves, so in my opinion the first question which decreases in relevance as tools improve. 

This leads us to the next point, just because we **can** do something, doesn't mean we should. The article raises good points and examples, so for the purposes of this response, I will simply recognize that the technology we create can potentially be used for evil. Not only can these algorithms provide means to do bad, they also make that power accessible to a wide range of entities - from individuals to governments.

Acknowledging the potential ethical concerns, we should not 'go gentle into that good night' and temper the rate at which we build tools and methods to answer the 'big questions' just to avoid moral conundrums. [2]For example, Pretty Good Privacy (PGP) encryption system was created by Phil Zimmermann at a time when it was illegal to export crypto-systems using keys larger than 40 bits [1]. After it's initial release, the US government persecuted Zimmermann [2] for "munitions export without a license." Today, PGP is one of the leading systems providing security and privacy to journalists, government officials, activists, and people from all walks of life. This is just one example of a technology being originally deemed 'dangerous' later proving itself a valuable resource for the common person. 

There is no question in my mind that the same natural text processing, machine learning, and data mining techniques will prove useful in contexts that provide no moral setbacks. As the stewards of our planet and society, I would assert that using these technologies is our responsibility - if algorithmically predicting natural disasters or disease outbreaks ahead of time is within the realm of possibility, is it not our obligation to do so?

While navigating the turmoil of ethical concerns may involve asking ourselves hard questions may be uncharted territory, as a society we must face the music, and accept our newfound duty.

[1] http://en.wikipedia.org/wiki/Pretty_Good_Privacy#Early_history

[2] While somewhat irrelevant to this topic, an interesting side note is that Zimmermann combatted his charges by printing PGP source code in hardback through MIT Press, in which form it fell under First Amendment protection.


