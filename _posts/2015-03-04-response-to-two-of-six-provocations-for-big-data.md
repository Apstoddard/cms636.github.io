---
layout: post
published: true
title: Response to Two of Six Provocations for Big Data
category: commentary
author: Val Healy
---

Reading Kate Crawford and danah boyd's article, "Six Provocations for Big Data," two of the six provocations expecially piqued my interest. I will reflect upon the pair of ideas below.

The first provocation is "Claims to Objectivity and Accuracy are Misleading." In this section, the authors explore the common conflation of quantification and objective truth. When considering Big Data, one is considerably more vulnerable to this conflation. After all, Big Data involves large, often diverse data sets. However, the process of analyzing the data necessarily involves some subjectivity. What data to include (or exclude for purposes of data cleaning)? Where should I get my data? Who is included, and who is left out? What questions are asked, and how are they interpreted by the researcher? Whatever your answers to these questions, your choice will always be subjective. This tension between claims of objectivity and the realities of subjectivity are not new to the humanities. Philosophers intent on establishing a generic human with an objective conception of reality have tried and failed, again and again. Just as each subject posesses their own conception of reality, each survey, dataset, and researcher has their own quirks, origins, and biases. Though seemingly inescapable, some measures can make explicit the biases involved, such as explicitly including research methods in the final presentation, as well as a discussion of the biases and gaps in the data and process.

The second provocation I would like to discuss is the final provocation, "Limited Access to Big Data Creates New Digital Divides," which discusses differentiated access to data. Companies' data is often sheathed in paywalls and other structural limitations. Some sets of data are only accessible to those working for the company, while others can only be accessed through exchanging currency. This produces an "unevenness in the system," which is worrying. Given, as a supporter of open source everything, I may be a bit biased; however, this inequality may have some ill effects, ranging from increased bias to the more nefarious. Who's to say a company would not withold data that would adversely affect their worth or reputation? Or that their in-house researchers might fudge or suppress the data's key findings? Drawing from the discussion of bias above, it is clear that a company's researchers have a significant source of bias: their wages. Furthermore, data analysis itself requires certain skills and knowledge, such as how to wrangle with an API. If researchers have only the technical skills, they may encounter the problems of bias detailed above. However, if the researcher has weak technical skills, the analysis may not be possible at all, or they might also be ignorant of statistical error or bias. 
