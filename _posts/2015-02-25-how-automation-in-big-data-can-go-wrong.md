---
layout: post
published: false
title: On Automation and Accessible Data
category: updates
---

**The (Limiting) Effects of Automation on Human Knowledge**
As someone directly involved with an automation-based project, I believe that automated procedures are extremely useful for  both efficiency and simplification of many difficult or time-consuming tasks. However there's a catch: you need to know exactly what you're doing, and what you're doing and what you want. In the case of collection and analysis of large sets of humanities data this is rarely the case, mainly because the collected data is often extremely versatile, and research questions are rarely quantitative. So as "data worshipers" (exemplified in the text by the Wired editor Chris Anderson) keep advocating the ineffability of numbers, it is critical that humanities scholars play an active role in the development of any tool for humanities big data.


**Accesability and Accountability**
The point made on data accessability and its implications on the use of public data was, in my opinion, somewhat less valid.'Just because content is publicly accessible doesnâ€™t mean that it was meant to be consumed by just anyone', is too bold of a statement. As new media for public information sharing arise and become popular, I believe that it becomes the users responsability to know and understand privacy and accontability settings of a given platform. Granted, boyd and Crawford's examples on violation of privacy are serious issues, however these technical flaws are often not intentionally incorporated by the researcher-they're merely bugs. A solution to this issue might be a stricter regulation of social and public data compiling software - potentiall even an IRB-like inspection, organized by people knowledgeble in the field encryption.